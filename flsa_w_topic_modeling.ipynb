{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from collections import Counter\n",
    "from FuzzyTM import FLSA_W\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "file_path = 'preprocessed_data_lda_flsa.pkl'\n",
    "\n",
    "# Read the data from the file\n",
    "with open(file_path, 'rb') as file:\n",
    "    prep_data = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def filter_word_from_corpus(data, words):\n",
    "    \"\"\"\n",
    "    Filters out specific words from the corpus.\n",
    "    Parameters:\n",
    "    - data : The corpus, represented by a list of list of tokens.\n",
    "    - words : The words to be filtered. Either a list of tokenized words or a single word.\n",
    "    Returns:\n",
    "    - List[List[str]]: Filtered data where specified words have been removed.\n",
    "    Example:\n",
    "    >> data = [[\"apple\", \"orange\"], [\"apple\", \"banana\"]]\n",
    "    >> filter_data(data, \"apple\")\n",
    "    [[\"orange\"], [\"banana\"]]\n",
    "    \"\"\"\n",
    "    # Ensure words is a list, even if a single string is passed\n",
    "    if isinstance(words, str):\n",
    "        words = [words]\n",
    "    # Filter words from data\n",
    "    filtered_data = [[token for token in row if token not in words] for row in data]\n",
    "    return filtered_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "flsaw = FLSA_W(input_file = prep_data,\n",
    "    num_topics = 10,\n",
    "    num_words = 10,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.0005*\"premarket\" + 0.0005*\"kuo\" + 0.0005*\"midday\" + 0.0004*\"chi\" + 0.0004*\"frankfurt\" + 0.0004*\"lite\" + 0.0004*\"forming\" + 0.0004*\"div\" + 0.0004*\"consolidation\" + 0.0004*\"tweeted\"'), (1, '0.0082*\"aapl\" + 0.0072*\"price\" + 0.0071*\"sale\" + 0.0071*\"share\" + 0.0068*\"report\" + 0.0068*\"product\" + 0.0067*\"million\" + 0.0065*\"service\" + 0.0065*\"next\" + 0.0065*\"inc\"'), (2, '0.0022*\"previously\" + 0.0014*\"planned\" + 0.0014*\"dec\" + 0.0013*\"cnbc\" + 0.0013*\"asian\" + 0.0012*\"yesterday\" + 0.0012*\"dispute\" + 0.0012*\"jones\" + 0.0012*\"lawsuit\" + 0.0012*\"donald\"'), (3, '0.0008*\"otc\" + 0.0008*\"thomson\" + 0.0008*\"taiwan\" + 0.0008*\"journal\" + 0.0007*\"aug\" + 0.0007*\"goog\" + 0.0007*\"finished\" + 0.0007*\"unveil\" + 0.0007*\"carl\" + 0.0007*\"ssnlf\"'), (4, '0.0022*\"version\" + 0.0022*\"york\" + 0.0022*\"chip\" + 0.0021*\"program\" + 0.0021*\"purchase\" + 0.0021*\"smartphones\" + 0.002*\"rival\" + 0.002*\"manufacturer\" + 0.002*\"larger\" + 0.002*\"computer\"'), (5, '0.0003*\"sma\" + 0.0003*\"fibonacci\" + 0.0003*\"kgi\" + 0.0003*\"consolidating\" + 0.0003*\"paschal\" + 0.0003*\"disputed\" + 0.0003*\"resellers\" + 0.0003*\"escrow\" + 0.0003*\"intra\" + 0.0003*\"solicitation\"'), (6, '0.0235*\"say\" + 0.0185*\"worker\" + 0.013*\"workforce\" + 0.0127*\"contractor\" + 0.0109*\"contingent\" + 0.0109*\"worked\" + 0.0106*\"employee\" + 0.0105*\"wilson\" + 0.0104*\"termination\" + 0.0103*\"contracting\"'), (7, '0.0003*\"otcpk\" + 0.0002*\"iovine\" + 0.0002*\"ssnnf\" + 0.0002*\"declares\" + 0.0002*\"tosyy\" + 0.0002*\"accuses\" + 0.0002*\"largan\" + 0.0002*\"collector\" + 0.0002*\"throttling\" + 0.0002*\"xinhua\"'), (8, '0.0105*\"silicon\" + 0.01*\"valley\" + 0.0099*\"work\" + 0.0094*\"people\" + 0.0089*\"handle\" + 0.0089*\"building\" + 0.0083*\"employment\" + 0.0082*\"former\" + 0.0079*\"internal\" + 0.0077*\"job\"'), (9, '0.004*\"iphones\" + 0.004*\"tuesday\" + 0.0039*\"launch\" + 0.0037*\"wednesday\" + 0.0035*\"store\" + 0.0035*\"sold\" + 0.0035*\"close\" + 0.0035*\"added\" + 0.0034*\"show\" + 0.0033*\"feature\"')]\n",
      "['premarket', 'kuo', 'midday', 'chi', 'frankfurt', 'lite', 'forming', 'div', 'consolidation', 'tweeted']\n",
      "0.4390202193145691\n",
      "1.0\n",
      "0.4390202193145691\n",
      "['aapl', 'price', 'sale', 'share', 'report', 'product', 'million', 'service', 'next', 'inc']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-14-a1dd544bc875>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mtopic\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mflsaw\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshow_topics\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrepresentation\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'words'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtopic\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mflsaw\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_coherence_score\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      9\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mflsaw\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_diversity_score\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mflsaw\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_interpretability_score\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\FuzzyTM\\FuzzyTM.py\u001B[0m in \u001B[0;36mget_coherence_score\u001B[1;34m(self, input_file, topics, coherence)\u001B[0m\n\u001B[0;32m   1030\u001B[0m         \u001B[0mid2word\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcorpora\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDictionary\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput_file\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1031\u001B[0m         \u001B[0mcorpus\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mid2word\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdoc2bow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mtext\u001B[0m \u001B[1;32min\u001B[0m \u001B[0minput_file\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1032\u001B[1;33m         self.coherence_score = CoherenceModel(\n\u001B[0m\u001B[0;32m   1033\u001B[0m             \u001B[0mtopics\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtopics\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtexts\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0minput_file\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcorpus\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcorpus\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1034\u001B[0m             \u001B[0mdictionary\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mid2word\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcoherence\u001B[0m\u001B[1;33m=\u001B[0m \u001B[0mcoherence\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\coherencemodel.py\u001B[0m in \u001B[0;36mget_coherence\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    612\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    613\u001B[0m         \"\"\"\n\u001B[1;32m--> 614\u001B[1;33m         \u001B[0mconfirmed_measures\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_coherence_per_topic\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    615\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0maggregate_measures\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconfirmed_measures\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    616\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\coherencemodel.py\u001B[0m in \u001B[0;36mget_coherence_per_topic\u001B[1;34m(self, segmented_topics, with_std, with_support)\u001B[0m\n\u001B[0;32m    572\u001B[0m             \u001B[0msegmented_topics\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmeasure\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mseg\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtopics\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    573\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_accumulator\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 574\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mestimate_probabilities\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msegmented_topics\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    575\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    576\u001B[0m         \u001B[0mkwargs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mwith_std\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mwith_std\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwith_support\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mwith_support\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\coherencemodel.py\u001B[0m in \u001B[0;36mestimate_probabilities\u001B[1;34m(self, segmented_topics)\u001B[0m\n\u001B[0;32m    544\u001B[0m                 \u001B[0mkwargs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'model'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeyed_vectors\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    545\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 546\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_accumulator\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmeasure\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprob\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    547\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    548\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_accumulator\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\topic_coherence\\probability_estimation.py\u001B[0m in \u001B[0;36mp_boolean_sliding_window\u001B[1;34m(texts, segmented_topics, dictionary, window_size, processes)\u001B[0m\n\u001B[0;32m    154\u001B[0m         \u001B[0maccumulator\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mParallelWordOccurrenceAccumulator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocesses\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtop_ids\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdictionary\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    155\u001B[0m     \u001B[0mlogger\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"using %s to estimate probabilities from sliding windows\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maccumulator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 156\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0maccumulator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0maccumulate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtexts\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwindow_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    157\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    158\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\topic_coherence\\text_analysis.py\u001B[0m in \u001B[0;36maccumulate\u001B[1;34m(self, texts, window_size)\u001B[0m\n\u001B[0;32m    435\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    436\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0maccumulate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtexts\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwindow_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 437\u001B[1;33m         \u001B[0mworkers\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_q\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutput_q\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstart_workers\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mwindow_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    438\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    439\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mqueue_all_texts\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput_q\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtexts\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwindow_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\topic_coherence\\text_analysis.py\u001B[0m in \u001B[0;36mstart_workers\u001B[1;34m(self, window_size)\u001B[0m\n\u001B[0;32m    469\u001B[0m             \u001B[0maccumulator\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mPatchedWordOccurrenceAccumulator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrelevant_ids\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdictionary\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    470\u001B[0m             \u001B[0mworker\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mAccumulatingWorker\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput_q\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutput_q\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maccumulator\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwindow_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 471\u001B[1;33m             \u001B[0mworker\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    472\u001B[0m             \u001B[0mworkers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mworker\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    473\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\process.py\u001B[0m in \u001B[0;36mstart\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    119\u001B[0m                \u001B[1;34m'daemonic processes are not allowed to have children'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    120\u001B[0m         \u001B[0m_cleanup\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 121\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_popen\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    122\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sentinel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_popen\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msentinel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    123\u001B[0m         \u001B[1;31m# Avoid a refcycle if the target function holds an indirect\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\context.py\u001B[0m in \u001B[0;36m_Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    222\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mstaticmethod\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    223\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 224\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0m_default_context\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mProcess\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    225\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    226\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mDefaultContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mBaseContext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\context.py\u001B[0m in \u001B[0;36m_Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    324\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    325\u001B[0m             \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mpopen_spawn_win32\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mPopen\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 326\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mPopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    327\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    328\u001B[0m     \u001B[1;32mclass\u001B[0m \u001B[0mSpawnContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mBaseContext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, process_obj)\u001B[0m\n\u001B[0;32m     91\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     92\u001B[0m                 \u001B[0mreduction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprep_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mto_child\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 93\u001B[1;33m                 \u001B[0mreduction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mto_child\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     94\u001B[0m             \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     95\u001B[0m                 \u001B[0mset_spawning_popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\reduction.py\u001B[0m in \u001B[0;36mdump\u001B[1;34m(obj, file, protocol)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprotocol\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     59\u001B[0m     \u001B[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 60\u001B[1;33m     \u001B[0mForkingPickler\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprotocol\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     61\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[1;31m#\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "flsaw.get_vocabulary_size()\n",
    "pwgt, ptgd = flsaw.get_matrices()\n",
    "print(flsaw.show_topics())\n",
    "\n",
    "\n",
    "for topic in flsaw.show_topics(representation='words'):\n",
    "    print(topic)\n",
    "    print(flsaw.get_coherence_score())\n",
    "    print(flsaw.get_diversity_score())\n",
    "    print(flsaw.get_interpretability_score())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#After training this model, remove the useless words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### IdeeÃ«n:\n",
    "- filter alle hulpwerkwoorden en bijwoorden eruit --> de stopwords zijn alleen nog maar de bezittelijke voornaamwoorden, en een deel van de hulpwerkwoorden"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "useless_words = ['whether', 'much', 'sharply']\n",
    "prep_data_it2 = filter_word_from_corpus(prep_data, useless_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "flsaw2 = FLSA_W(input_file = prep_data_it2,\n",
    "    num_topics = 10,\n",
    "    num_words = 10,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "flsaw2.get_vocabulary_size()\n",
    "pwgt, ptgd = flsaw2.get_matrices()\n",
    "print(flsaw2.show_topics())\n",
    "\n",
    "\n",
    "for topic in flsaw2.show_topics(representation='words'):\n",
    "    print(topic)\n",
    "    print(flsaw2.get_coherence_score())\n",
    "    print(flsaw2.get_diversity_score())\n",
    "    print(flsaw2.get_interpretability_score())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#filtering words:\n",
    "#randewich is a journalist, jimmy not much saying\n",
    "useless_words_it3 = ['randewich', 'eddy', 'unnamed', 'next']\n",
    "prep_data_it3 = filter_word_from_corpus(prep_data, useless_words_it3)\n",
    "flsaw3 = FLSA_W(input_file=prep_data_it3,\n",
    "                num_topics=10,\n",
    "                num_words=10,\n",
    "                )\n",
    "flsaw3.get_vocabulary_size()\n",
    "pwgt, ptgd = flsaw3.get_matrices()\n",
    "print(flsaw3.show_topics())\n",
    "\n",
    "for topic in flsaw3.show_topics(representation='words'):\n",
    "    print(topic)\n",
    "    print(flsaw3.get_coherence_score())\n",
    "    print(flsaw3.get_diversity_score())\n",
    "    print(flsaw3.get_interpretability_score())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}